{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images to data\\pizza_steak_sushi...\n",
      "Unzipping...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from email.mime import image\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data/')\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} already exists\")\n",
    "else:\n",
    "    print(f\"Downloading images to {image_path}...\")\n",
    "    r = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    with open('pizza_steak.zip', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Unzipping...\")\n",
    "    zip_ref = zipfile.ZipFile('pizza_steak.zip', 'r')\n",
    "    zip_ref.extractall(data_path)\n",
    "    zip_ref.close()\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/test'),\n",
       " WindowsPath('data/pizza_steak_sushi/train'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "test_dir, train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 75)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "\n",
    "# Create a simple transform\n",
    "data_transforms = transforms.Compose([\n",
    "    Resize((64,64)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Use the ImageFolder to create dataset(s)\n",
    "train_dataset = ImageFolder(root='data/train', \n",
    "                            transform=data_transforms,\n",
    "                            target_transform=None) # Transform to perform on labels if needed\n",
    "\n",
    "test_dataset = ImageFolder(root='data/test',\n",
    "                        transform=data_transforms)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pizza', 'steak', 'sushi']\n",
      "{'pizza': 0, 'steak': 1, 'sushi': 2}\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "print(class_names)\n",
    "\n",
    "class_dict = train_dataset.class_to_idx\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x241a998d6d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x241a998d6d0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                            batch_size=1,\n",
    "                            num_workers=1, # How many subprocesses to use for data loading\n",
    "                            shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False)\n",
    "\n",
    "train_dataloader, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Image shape: torch.Size([1, 3, 64, 64])\n",
      "      Label shape: torch.Size([1])\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"\"\"\n",
    "      Image shape: {img.shape}\n",
    "      Label shape: {label.shape}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a TinyVGG Model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates the TinyVGG architecture.\n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "    input_shape: An integer indicating number of input channels.\n",
    "    hidden_units: An integer indicating number of hidden units between layers.\n",
    "    output_shape: An integer indicating number of output units.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                input_shape: int = 3,\n",
    "                hidden_units: int = 64,\n",
    "                output_shape: int = 3) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                        stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                    out_features=output_shape))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.classifier(\n",
    "                    self.conv_block_2(\n",
    "                        self.conv_block_1(x)\n",
    "                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=16384, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Instantiate model\n",
    "model_0 = TinyVGG(input_shape=3, hidden_units=64, output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output logits:\n",
      "tensor([[ 0.0189, -0.0017,  0.0222]], device='cuda:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.3352, 0.3284, 0.3364]], device='cuda:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([2], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Create a train and test_step function\n",
    "import torch\n",
    "def train_step(model: nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer, \n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for one epoch.\n",
    "    \n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model instance.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "            If not specified, the device will be \"cuda\" if available.\n",
    "    \n",
    "    Returns:\n",
    "        A Tuple of training loss and training accuracy metrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Instantiate training loss and accuracy\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        \n",
    "        # Calculate loss and accumulate train loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "    \n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "    \n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "  \n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "  \n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "                # Send data to target device\n",
    "                X, y = X.to(device), y.to(device)\n",
    "        \n",
    "                # 1. Forward pass\n",
    "                test_pred_logits = model(X)\n",
    "\n",
    "                # 2. Calculate and accumulate loss\n",
    "                loss = loss_fn(test_pred_logits, y)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Calculate and accumulate accuracy\n",
    "                test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "                test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "          \n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List[float]]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "  }\n",
    "  \n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "      \n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "  \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "  Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "  \n",
    "  Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "  \"\"\"\n",
    "  # Create target directory\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "  \n",
    "  # Create model save path\n",
    "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  # Save the model state_dict()\n",
    "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795726c0617a4c1887223d006d37e8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1182 | train_acc: 0.2978 | test_loss: 1.0972 | test_acc: 0.4133\n",
      "Epoch: 2 | train_loss: 1.1012 | train_acc: 0.3022 | test_loss: 1.0995 | test_acc: 0.2533\n",
      "Epoch: 3 | train_loss: 1.0992 | train_acc: 0.3111 | test_loss: 1.0998 | test_acc: 0.3333\n",
      "Epoch: 4 | train_loss: 1.0990 | train_acc: 0.3378 | test_loss: 1.1001 | test_acc: 0.3333\n",
      "Epoch: 5 | train_loss: 1.0988 | train_acc: 0.3200 | test_loss: 1.1006 | test_acc: 0.3333\n",
      "[INFO] Total training time: 21.686 seconds\n",
      "[INFO] Saving model to: models\\05_going_modular_cell_mode_tinyvgg_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "# Save the model\n",
    "save_model(model=model_0,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"05_going_modular_cell_mode_tinyvgg_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets and Dataloaders in Script Mode\n",
    "\n",
    "Use the Juypter Magic command to create a `.py` script\n",
    "\n",
    "This save's a code cell's contents to a file using the Juypter magic `%%writefile filename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going_modular directory already exists\n"
     ]
    }
   ],
   "source": [
    "# Create a directory going_modular\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if the directory already exists\n",
    "if os.path.isdir('going_modular'):\n",
    "    print(\"going_modular directory already exists\")\n",
    "else:\n",
    "    os.mkdir('going_modular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for image classification datasets.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int = NUM_WORKERS\n",
    "):\n",
    "    \"\"\"\n",
    "    Create dataloaders for training and testing datasets.\n",
    "    \n",
    "    Args:\n",
    "        train_dir (str): The directory path of the training dataset.\n",
    "        test_dir (str): The directory path of the testing dataset.\n",
    "        transform (torchvision.transforms.Compose): The transformation to apply to the images.\n",
    "        batch_size (int): The batch size for the dataloaders.\n",
    "        num_workers (int, optional): The number of worker processes for data loading. Defaults to NUM_WORKERS.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the training dataloader, testing dataloader, and class names.\n",
    "    \"\"\"\n",
    "    train_dataset = ImageFolder(root=train_dir, \n",
    "                                transform=transform,\n",
    "                                target_transform=None) # Transform to perform on labels if needed\n",
    "\n",
    "    test_dataset = ImageFolder(root=test_dir,\n",
    "                               transform=transform)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, \n",
    "                                  batch_size=batch_size,\n",
    "                                  num_workers=num_workers, # How many subprocesses to use for data loading\n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=True) # If true, the data loader will copy Tensors into CUDA pinned memory before returning them\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=num_workers, # How many subprocesses to use for data loading\n",
    "                                 shuffle=False,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    class_names = train_dataset.classes\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:\\\\Users\\\\jakev\\\\Code\\\\Learn_Pytorch\\\\Practice\\\\data\\\\train'\n",
    "test_dir = 'C:\\\\Users\\\\jakev\\Code\\\\Learn_Pytorch\\\\Practice\\\\data\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x24366615e90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x241a9d4c690>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from going_modular import data_setup\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=data_transforms,\n",
    "                                                                               batch_size=32)\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/model_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch computer vision models. \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates the TinyVGG architecture.\n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "    input_shape: An integer indicating number of input channels.\n",
    "    hidden_units: An integer indicating number of hidden units between layers.\n",
    "    output_shape: An integer indicating number of output units.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                input_shape: int = 3,\n",
    "                hidden_units: int = 64,\n",
    "                output_shape: int = 3) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                        stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                    out_features=output_shape))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.classifier(\n",
    "                    self.conv_block_2(\n",
    "                        self.conv_block_1(x)\n",
    "                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.0392, -0.1832,  0.1811],\n",
       "                        [ 0.0482,  0.0717, -0.1301],\n",
       "                        [ 0.1239, -0.1029, -0.0437]],\n",
       "              \n",
       "                       [[-0.0912, -0.1740,  0.1270],\n",
       "                        [-0.0854,  0.0818, -0.1743],\n",
       "                        [-0.1581, -0.1337, -0.1644]],\n",
       "              \n",
       "                       [[-0.0010,  0.0632, -0.1180],\n",
       "                        [-0.0927,  0.1662,  0.1698],\n",
       "                        [-0.0702, -0.1762,  0.0872]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1087, -0.0078, -0.1267],\n",
       "                        [-0.1430,  0.0171,  0.0134],\n",
       "                        [-0.0361,  0.0922,  0.1769]],\n",
       "              \n",
       "                       [[ 0.1547, -0.1376,  0.1208],\n",
       "                        [-0.1004,  0.1757, -0.1643],\n",
       "                        [-0.0065,  0.1217, -0.0438]],\n",
       "              \n",
       "                       [[ 0.0218, -0.1345, -0.0816],\n",
       "                        [-0.0935,  0.1436,  0.1406],\n",
       "                        [ 0.0054, -0.1914, -0.0169]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1421, -0.0685, -0.1695],\n",
       "                        [ 0.0483,  0.1655,  0.0907],\n",
       "                        [ 0.1802, -0.0937,  0.1010]],\n",
       "              \n",
       "                       [[-0.0279, -0.0207,  0.1846],\n",
       "                        [ 0.0536, -0.0979,  0.1059],\n",
       "                        [-0.1076, -0.0063, -0.1837]],\n",
       "              \n",
       "                       [[-0.0573, -0.0378, -0.0166],\n",
       "                        [ 0.0668,  0.0642,  0.0354],\n",
       "                        [ 0.1087, -0.1135,  0.0556]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1269, -0.0394, -0.0366],\n",
       "                        [ 0.0635, -0.1909,  0.1853],\n",
       "                        [ 0.1217, -0.1402, -0.0767]],\n",
       "              \n",
       "                       [[-0.1428, -0.1001,  0.0420],\n",
       "                        [-0.0147,  0.1295,  0.1137],\n",
       "                        [ 0.1604, -0.0274, -0.1486]],\n",
       "              \n",
       "                       [[-0.0750,  0.1581, -0.1740],\n",
       "                        [ 0.1625,  0.1285, -0.0809],\n",
       "                        [-0.0148, -0.1016,  0.1505]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0224,  0.0333, -0.0428],\n",
       "                        [ 0.1454, -0.0058,  0.1389],\n",
       "                        [ 0.0558,  0.0011,  0.1175]],\n",
       "              \n",
       "                       [[ 0.0126,  0.0123, -0.0746],\n",
       "                        [-0.1132, -0.0851, -0.1810],\n",
       "                        [ 0.1486,  0.1317, -0.0848]],\n",
       "              \n",
       "                       [[ 0.1384, -0.1726, -0.1739],\n",
       "                        [ 0.1617,  0.0148,  0.0038],\n",
       "                        [-0.0387,  0.1791,  0.0408]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0154,  0.1784,  0.0040],\n",
       "                        [-0.1841,  0.0840,  0.0842],\n",
       "                        [-0.1140,  0.0334,  0.0055]],\n",
       "              \n",
       "                       [[-0.0293, -0.0289,  0.1108],\n",
       "                        [ 0.0316, -0.1776,  0.1886],\n",
       "                        [ 0.0810, -0.1650,  0.1500]],\n",
       "              \n",
       "                       [[-0.1366, -0.0430, -0.0618],\n",
       "                        [-0.0650,  0.0308,  0.0335],\n",
       "                        [ 0.0617,  0.0265, -0.1587]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0264, -0.0085, -0.0474],\n",
       "                        [-0.1662, -0.1777,  0.1330],\n",
       "                        [-0.0990,  0.1061,  0.1312]],\n",
       "              \n",
       "                       [[ 0.0677, -0.0669, -0.0934],\n",
       "                        [ 0.1607,  0.1507,  0.1133],\n",
       "                        [ 0.1665, -0.1533,  0.0183]],\n",
       "              \n",
       "                       [[-0.1640,  0.0487,  0.0064],\n",
       "                        [-0.1788, -0.0474, -0.0122],\n",
       "                        [-0.0258,  0.1138, -0.1568]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1246, -0.0457,  0.1205],\n",
       "                        [-0.1598,  0.1195,  0.0752],\n",
       "                        [ 0.1256, -0.0905, -0.1295]],\n",
       "              \n",
       "                       [[ 0.0601,  0.0514,  0.1553],\n",
       "                        [ 0.0186,  0.0901, -0.0535],\n",
       "                        [-0.0365, -0.1157,  0.1016]],\n",
       "              \n",
       "                       [[ 0.0744, -0.1375,  0.0580],\n",
       "                        [ 0.1220,  0.1011,  0.0944],\n",
       "                        [-0.1819,  0.0639,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0703, -0.0484, -0.0547],\n",
       "                        [ 0.1289, -0.0939,  0.0250],\n",
       "                        [ 0.1861,  0.1600,  0.0794]],\n",
       "              \n",
       "                       [[ 0.1424, -0.1466,  0.0162],\n",
       "                        [-0.1272, -0.0798,  0.1568],\n",
       "                        [ 0.1512,  0.1312, -0.0943]],\n",
       "              \n",
       "                       [[-0.0388,  0.1790,  0.0805],\n",
       "                        [-0.0888,  0.1443, -0.0716],\n",
       "                        [ 0.1756, -0.1009,  0.0170]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0790, -0.1190, -0.0447],\n",
       "                        [ 0.0526, -0.0626,  0.1416],\n",
       "                        [-0.0739, -0.0727, -0.1254]],\n",
       "              \n",
       "                       [[-0.0879,  0.1346,  0.1841],\n",
       "                        [-0.1488,  0.0692,  0.1116],\n",
       "                        [-0.0991, -0.1719,  0.0486]],\n",
       "              \n",
       "                       [[-0.1756,  0.0411,  0.1660],\n",
       "                        [ 0.0107,  0.1316,  0.1266],\n",
       "                        [ 0.1075, -0.0639, -0.0787]]]], device='cuda:0')),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([-0.1755, -0.1128,  0.1036,  0.0842, -0.1094,  0.0278, -0.0285,  0.0970,\n",
       "                      -0.1050, -0.0077], device='cuda:0')),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[ 0.0251,  0.0133, -0.0284],\n",
       "                        [ 0.0608, -0.0707, -0.0233],\n",
       "                        [-0.0918,  0.0473, -0.0521]],\n",
       "              \n",
       "                       [[ 0.0528, -0.0132, -0.0422],\n",
       "                        [ 0.0805, -0.0741,  0.0592],\n",
       "                        [ 0.0903, -0.0982,  0.0426]],\n",
       "              \n",
       "                       [[-0.0925,  0.0562, -0.0666],\n",
       "                        [-0.0311, -0.0522,  0.0485],\n",
       "                        [-0.0081, -0.0845, -0.0787]],\n",
       "              \n",
       "                       [[-0.0091, -0.0653,  0.0119],\n",
       "                        [ 0.0753,  0.0517,  0.0214],\n",
       "                        [ 0.1022,  0.0320, -0.0162]],\n",
       "              \n",
       "                       [[-0.0789,  0.0169, -0.0780],\n",
       "                        [-0.0080, -0.0835, -0.0513],\n",
       "                        [-0.0437,  0.0106,  0.0194]],\n",
       "              \n",
       "                       [[-0.0073, -0.0523, -0.0988],\n",
       "                        [ 0.0325,  0.0985,  0.0710],\n",
       "                        [-0.0708, -0.0909, -0.0913]],\n",
       "              \n",
       "                       [[-0.0738, -0.0694,  0.0974],\n",
       "                        [-0.0286,  0.0544,  0.0434],\n",
       "                        [ 0.0392, -0.1029,  0.1027]],\n",
       "              \n",
       "                       [[ 0.0651, -0.0982, -0.0693],\n",
       "                        [ 0.0439, -0.0217, -0.0741],\n",
       "                        [ 0.0194, -0.0990,  0.0848]],\n",
       "              \n",
       "                       [[ 0.0877,  0.0552,  0.0490],\n",
       "                        [-0.0655, -0.0107,  0.0523],\n",
       "                        [ 0.0258,  0.0866,  0.0238]],\n",
       "              \n",
       "                       [[-0.0839, -0.0671,  0.0748],\n",
       "                        [ 0.0653,  0.0264,  0.0153],\n",
       "                        [ 0.0616, -0.1031, -0.1015]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0521, -0.0503, -0.0121],\n",
       "                        [ 0.0457, -0.0283,  0.0021],\n",
       "                        [-0.0811, -0.0438,  0.0825]],\n",
       "              \n",
       "                       [[ 0.0839, -0.0266,  0.0413],\n",
       "                        [ 0.0871,  0.0778, -0.0022],\n",
       "                        [-0.0681, -0.0314,  0.0569]],\n",
       "              \n",
       "                       [[-0.0482,  0.0539, -0.0760],\n",
       "                        [ 0.0461,  0.0660, -0.0186],\n",
       "                        [ 0.1045,  0.0642,  0.0023]],\n",
       "              \n",
       "                       [[-0.0231,  0.0079, -0.0590],\n",
       "                        [-0.0153, -0.0974,  0.0354],\n",
       "                        [ 0.0124, -0.0823, -0.0238]],\n",
       "              \n",
       "                       [[ 0.0370, -0.0667,  0.0425],\n",
       "                        [-0.0764,  0.0056, -0.0141],\n",
       "                        [-0.0776, -0.0169, -0.0501]],\n",
       "              \n",
       "                       [[-0.0190,  0.0120, -0.0167],\n",
       "                        [-0.0120,  0.0843,  0.0814],\n",
       "                        [-0.0545,  0.0139,  0.0396]],\n",
       "              \n",
       "                       [[ 0.0071,  0.0083, -0.0405],\n",
       "                        [ 0.0193, -0.0612, -0.0224],\n",
       "                        [-0.0462,  0.0361,  0.0368]],\n",
       "              \n",
       "                       [[-0.0903, -0.0831,  0.0020],\n",
       "                        [ 0.0317, -0.1010,  0.0082],\n",
       "                        [-0.0630, -0.0910,  0.0925]],\n",
       "              \n",
       "                       [[-0.0676, -0.0503,  0.1019],\n",
       "                        [-0.0631, -0.0430, -0.0637],\n",
       "                        [-0.0553,  0.0124,  0.0550]],\n",
       "              \n",
       "                       [[ 0.0344, -0.0304,  0.0279],\n",
       "                        [-0.0775,  0.0793, -0.0753],\n",
       "                        [ 0.0484, -0.0813, -0.0448]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0959,  0.0157,  0.0524],\n",
       "                        [-0.0731,  0.0387, -0.0246],\n",
       "                        [ 0.0218, -0.0720, -0.0781]],\n",
       "              \n",
       "                       [[-0.0153,  0.0421, -0.1027],\n",
       "                        [-0.0690, -0.0800, -0.0180],\n",
       "                        [-0.0757, -0.0568, -0.0484]],\n",
       "              \n",
       "                       [[-0.0715, -0.0619, -0.0460],\n",
       "                        [-0.0284,  0.0852, -0.0044],\n",
       "                        [ 0.0895,  0.0097,  0.0493]],\n",
       "              \n",
       "                       [[ 0.0376, -0.0061,  0.0993],\n",
       "                        [-0.0609, -0.0288,  0.0188],\n",
       "                        [ 0.0084, -0.0400,  0.0588]],\n",
       "              \n",
       "                       [[-0.0959,  0.0965,  0.0268],\n",
       "                        [-0.0154,  0.0949, -0.0397],\n",
       "                        [-0.1034, -0.0752,  0.0854]],\n",
       "              \n",
       "                       [[-0.0562,  0.0302, -0.0304],\n",
       "                        [ 0.0676, -0.0441,  0.0901],\n",
       "                        [ 0.0934,  0.0063, -0.0802]],\n",
       "              \n",
       "                       [[ 0.0154, -0.0499, -0.0779],\n",
       "                        [-0.0259, -0.0169,  0.0192],\n",
       "                        [-0.0134,  0.0184, -0.0152]],\n",
       "              \n",
       "                       [[-0.1047,  0.0045,  0.0282],\n",
       "                        [ 0.0822, -0.0931, -0.0461],\n",
       "                        [-0.0650, -0.0284, -0.0490]],\n",
       "              \n",
       "                       [[ 0.0951, -0.0773, -0.0728],\n",
       "                        [-0.0108,  0.0250,  0.0959],\n",
       "                        [ 0.0225,  0.0913,  0.0271]],\n",
       "              \n",
       "                       [[-0.0970,  0.0280,  0.0170],\n",
       "                        [-0.0243,  0.0339, -0.0614],\n",
       "                        [ 0.0953, -0.0715,  0.1036]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0769,  0.0749, -0.0287],\n",
       "                        [-0.0933,  0.0730, -0.0857],\n",
       "                        [-0.0842, -0.0065, -0.0802]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0838, -0.0221],\n",
       "                        [-0.0301, -0.0556,  0.0354],\n",
       "                        [ 0.0172,  0.0808, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0303, -0.0682,  0.0587],\n",
       "                        [-0.0285,  0.0935, -0.0351],\n",
       "                        [-0.1032, -0.0127,  0.0986]],\n",
       "              \n",
       "                       [[-0.0579,  0.0164, -0.0368],\n",
       "                        [-0.0446,  0.0435, -0.0353],\n",
       "                        [-0.0731,  0.0967, -0.0832]],\n",
       "              \n",
       "                       [[-0.0174,  0.1027, -0.0117],\n",
       "                        [ 0.0385,  0.0835, -0.0020],\n",
       "                        [-0.0189, -0.0194,  0.0399]],\n",
       "              \n",
       "                       [[-0.0140,  0.0968,  0.0013],\n",
       "                        [-0.0846,  0.0855,  0.0246],\n",
       "                        [ 0.0321,  0.0018,  0.0732]],\n",
       "              \n",
       "                       [[-0.0756, -0.0245, -0.0991],\n",
       "                        [-0.0152, -0.1051,  0.0910],\n",
       "                        [-0.0870, -0.0057, -0.0583]],\n",
       "              \n",
       "                       [[ 0.0390,  0.0051,  0.0071],\n",
       "                        [ 0.0660,  0.0867,  0.0987],\n",
       "                        [-0.0402, -0.0477,  0.0873]],\n",
       "              \n",
       "                       [[ 0.0467,  0.0122, -0.0536],\n",
       "                        [-0.0809,  0.0616,  0.0187],\n",
       "                        [ 0.0950,  0.0040,  0.0806]],\n",
       "              \n",
       "                       [[ 0.0109,  0.0056,  0.0235],\n",
       "                        [ 0.0821,  0.0649,  0.0949],\n",
       "                        [ 0.0168,  0.0535,  0.0211]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0740,  0.0415, -0.0128],\n",
       "                        [ 0.0204, -0.0071, -0.0396],\n",
       "                        [-0.0472, -0.0022,  0.0806]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0680,  0.0521],\n",
       "                        [-0.0504,  0.0140,  0.0948],\n",
       "                        [ 0.0598, -0.0768, -0.0726]],\n",
       "              \n",
       "                       [[ 0.1006,  0.0061, -0.0921],\n",
       "                        [ 0.0248,  0.0328, -0.0131],\n",
       "                        [ 0.0582, -0.0840,  0.0151]],\n",
       "              \n",
       "                       [[-0.0294, -0.0054,  0.0006],\n",
       "                        [ 0.1006, -0.0313, -0.1024],\n",
       "                        [-0.0658, -0.0407,  0.0866]],\n",
       "              \n",
       "                       [[ 0.0313, -0.0670,  0.0140],\n",
       "                        [ 0.0510, -0.0119,  0.0029],\n",
       "                        [-0.0672,  0.0137, -0.0900]],\n",
       "              \n",
       "                       [[-0.0361,  0.0211,  0.0314],\n",
       "                        [-0.0823, -0.0110,  0.0624],\n",
       "                        [ 0.1003, -0.0131,  0.0435]],\n",
       "              \n",
       "                       [[ 0.0064, -0.0674,  0.0107],\n",
       "                        [-0.0669, -0.0048, -0.0827],\n",
       "                        [-0.0563, -0.0297, -0.0094]],\n",
       "              \n",
       "                       [[-0.0834, -0.0358, -0.1042],\n",
       "                        [-0.0809, -0.0978, -0.0695],\n",
       "                        [-0.0061,  0.0692,  0.0048]],\n",
       "              \n",
       "                       [[-0.0994,  0.0876, -0.0707],\n",
       "                        [-0.0449,  0.0263, -0.0336],\n",
       "                        [ 0.0112, -0.0285, -0.0041]],\n",
       "              \n",
       "                       [[-0.0994,  0.0026,  0.0118],\n",
       "                        [ 0.0644,  0.0001,  0.0629],\n",
       "                        [ 0.0027,  0.0518, -0.0389]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0123,  0.0015, -0.0798],\n",
       "                        [ 0.1046,  0.0720,  0.0516],\n",
       "                        [-0.0870,  0.0988,  0.0997]],\n",
       "              \n",
       "                       [[-0.0048, -0.0112,  0.0883],\n",
       "                        [-0.0870,  0.1004, -0.0267],\n",
       "                        [-0.0478,  0.0051,  0.0310]],\n",
       "              \n",
       "                       [[ 0.0106,  0.0678, -0.0846],\n",
       "                        [-0.0073, -0.0073, -0.0726],\n",
       "                        [-0.0807, -0.0384, -0.0364]],\n",
       "              \n",
       "                       [[ 0.0081, -0.0454,  0.0967],\n",
       "                        [ 0.0383, -0.0515, -0.0139],\n",
       "                        [-0.0907,  0.0484, -0.0528]],\n",
       "              \n",
       "                       [[ 0.0817,  0.0571, -0.0374],\n",
       "                        [ 0.0124, -0.0167, -0.0880],\n",
       "                        [-0.0730, -0.0562,  0.1004]],\n",
       "              \n",
       "                       [[-0.0739,  0.0473, -0.0422],\n",
       "                        [ 0.0364,  0.0751,  0.0717],\n",
       "                        [-0.0896,  0.0047,  0.0278]],\n",
       "              \n",
       "                       [[ 0.0127,  0.0045,  0.1032],\n",
       "                        [-0.0828,  0.0216,  0.0217],\n",
       "                        [ 0.0875,  0.0538, -0.0388]],\n",
       "              \n",
       "                       [[-0.0077, -0.0786,  0.0085],\n",
       "                        [ 0.0112,  0.0911,  0.0937],\n",
       "                        [-0.0742,  0.1008, -0.0923]],\n",
       "              \n",
       "                       [[ 0.0280,  0.0523,  0.0569],\n",
       "                        [ 0.0808, -0.0286,  0.0898],\n",
       "                        [ 0.0112,  0.0020, -0.0359]],\n",
       "              \n",
       "                       [[-0.0919, -0.0292, -0.0035],\n",
       "                        [ 0.0118, -0.0161, -0.0055],\n",
       "                        [ 0.0050, -0.0585, -0.0070]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0898,  0.0051,  0.0926],\n",
       "                        [-0.0501,  0.0639, -0.0343],\n",
       "                        [-0.0457,  0.0501, -0.1032]],\n",
       "              \n",
       "                       [[ 0.0668,  0.0695,  0.0365],\n",
       "                        [-0.0035, -0.0497, -0.0672],\n",
       "                        [ 0.0953,  0.0498,  0.0559]],\n",
       "              \n",
       "                       [[-0.0659,  0.0631, -0.0648],\n",
       "                        [ 0.0796,  0.0813, -0.0962],\n",
       "                        [-0.0985, -0.0928, -0.0492]],\n",
       "              \n",
       "                       [[ 0.0296, -0.0939,  0.0887],\n",
       "                        [-0.0676, -0.0336,  0.0246],\n",
       "                        [-0.0596, -0.0047, -0.0915]],\n",
       "              \n",
       "                       [[-0.0943,  0.0068, -0.0426],\n",
       "                        [ 0.0754, -0.0602,  0.0590],\n",
       "                        [ 0.0776, -0.0281, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0329, -0.0571,  0.0296],\n",
       "                        [-0.0307, -0.0262, -0.0835],\n",
       "                        [ 0.0848, -0.0911, -0.0190]],\n",
       "              \n",
       "                       [[ 0.0429, -0.0734,  0.0085],\n",
       "                        [ 0.1015,  0.0306,  0.0729],\n",
       "                        [-0.0796,  0.0550,  0.0050]],\n",
       "              \n",
       "                       [[ 0.0122, -0.0386, -0.0231],\n",
       "                        [ 0.0644,  0.0645, -0.0826],\n",
       "                        [ 0.0902,  0.0998, -0.0370]],\n",
       "              \n",
       "                       [[ 0.0137,  0.0575, -0.1030],\n",
       "                        [ 0.0388,  0.0925, -0.0299],\n",
       "                        [-0.0865, -0.0652,  0.0672]],\n",
       "              \n",
       "                       [[-0.0068, -0.0057,  0.0167],\n",
       "                        [ 0.0360,  0.0617,  0.0048],\n",
       "                        [-0.1026,  0.0689,  0.0663]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0073, -0.0590, -0.0234],\n",
       "                        [ 0.0464,  0.0782, -0.0942],\n",
       "                        [ 0.0176,  0.0095,  0.0247]],\n",
       "              \n",
       "                       [[-0.0259, -0.0092, -0.1022],\n",
       "                        [-0.0082, -0.0885,  0.0901],\n",
       "                        [ 0.0417,  0.0387, -0.0547]],\n",
       "              \n",
       "                       [[-0.0443,  0.0120, -0.0184],\n",
       "                        [-0.0016,  0.0103,  0.0007],\n",
       "                        [-0.0906,  0.1008, -0.0442]],\n",
       "              \n",
       "                       [[ 0.0145, -0.0684,  0.0929],\n",
       "                        [-0.0490,  0.0579,  0.0402],\n",
       "                        [-0.0182,  0.0239, -0.0778]],\n",
       "              \n",
       "                       [[-0.0949,  0.0572,  0.0661],\n",
       "                        [-0.0870, -0.0353, -0.0971],\n",
       "                        [-0.0871,  0.0170, -0.0253]],\n",
       "              \n",
       "                       [[ 0.1009,  0.0787, -0.0623],\n",
       "                        [ 0.0858,  0.0615,  0.0937],\n",
       "                        [-0.0287, -0.0045, -0.0570]],\n",
       "              \n",
       "                       [[-0.0484,  0.0962,  0.0806],\n",
       "                        [-0.1051,  0.0549, -0.0380],\n",
       "                        [-0.0829,  0.0483,  0.0174]],\n",
       "              \n",
       "                       [[-0.0297,  0.1050, -0.0653],\n",
       "                        [ 0.0627,  0.0660, -0.0524],\n",
       "                        [ 0.0586, -0.0525, -0.0487]],\n",
       "              \n",
       "                       [[ 0.0720,  0.0885, -0.0710],\n",
       "                        [ 0.1018, -0.1009,  0.0437],\n",
       "                        [-0.0927, -0.0205, -0.0885]],\n",
       "              \n",
       "                       [[ 0.0854, -0.0620, -0.0932],\n",
       "                        [-0.0460,  0.0671,  0.0404],\n",
       "                        [ 0.0430,  0.0780, -0.0257]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0577, -0.0961, -0.0841],\n",
       "                        [ 0.0581, -0.0756,  0.0297],\n",
       "                        [ 0.0324,  0.0612,  0.0778]],\n",
       "              \n",
       "                       [[ 0.0266, -0.0084, -0.0918],\n",
       "                        [-0.0536, -0.0268,  0.0442],\n",
       "                        [-0.0647, -0.0280, -0.0023]],\n",
       "              \n",
       "                       [[-0.0014, -0.0744,  0.0613],\n",
       "                        [ 0.0131,  0.0895, -0.0798],\n",
       "                        [ 0.0007,  0.0306,  0.0498]],\n",
       "              \n",
       "                       [[-0.0823, -0.0487, -0.0004],\n",
       "                        [-0.0665, -0.0839,  0.0135],\n",
       "                        [ 0.0612, -0.1020, -0.0333]],\n",
       "              \n",
       "                       [[-0.1043,  0.0188,  0.0359],\n",
       "                        [-0.0960,  0.0278, -0.0353],\n",
       "                        [-0.0197, -0.0788, -0.0122]],\n",
       "              \n",
       "                       [[ 0.0493, -0.0577, -0.0366],\n",
       "                        [-0.0624, -0.0485,  0.0881],\n",
       "                        [ 0.0719, -0.0476,  0.1042]],\n",
       "              \n",
       "                       [[ 0.0396,  0.0341, -0.0807],\n",
       "                        [-0.0262,  0.0931,  0.0696],\n",
       "                        [ 0.0544, -0.0508, -0.0262]],\n",
       "              \n",
       "                       [[ 0.0435,  0.0356, -0.0323],\n",
       "                        [-0.0536, -0.0851, -0.0840],\n",
       "                        [-0.0436,  0.0556, -0.0513]],\n",
       "              \n",
       "                       [[ 0.0343, -0.0739, -0.0033],\n",
       "                        [-0.0629, -0.0487,  0.0635],\n",
       "                        [ 0.0279,  0.0930,  0.0269]],\n",
       "              \n",
       "                       [[ 0.0026,  0.0855, -0.0739],\n",
       "                        [ 0.0609, -0.0003, -0.0031],\n",
       "                        [-0.0654, -0.0005, -0.0678]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0608, -0.0700, -0.0108],\n",
       "                        [ 0.0999, -0.0089, -0.0845],\n",
       "                        [ 0.0265,  0.0271, -0.0524]],\n",
       "              \n",
       "                       [[-0.0899, -0.1053, -0.0569],\n",
       "                        [ 0.0028, -0.0945, -0.0883],\n",
       "                        [ 0.0324, -0.0851,  0.0007]],\n",
       "              \n",
       "                       [[ 0.0288,  0.0936, -0.0002],\n",
       "                        [ 0.0260,  0.0814,  0.0271],\n",
       "                        [ 0.0939, -0.0158,  0.1038]],\n",
       "              \n",
       "                       [[-0.0656,  0.0731,  0.0162],\n",
       "                        [-0.0043,  0.1009,  0.0510],\n",
       "                        [ 0.0162, -0.0246,  0.0901]],\n",
       "              \n",
       "                       [[ 0.0066,  0.0244, -0.0070],\n",
       "                        [-0.0394, -0.0562,  0.0577],\n",
       "                        [ 0.0190,  0.0170,  0.0051]],\n",
       "              \n",
       "                       [[-0.0383, -0.0043, -0.0530],\n",
       "                        [ 0.0108,  0.0484, -0.1007],\n",
       "                        [ 0.0907, -0.0311,  0.0842]],\n",
       "              \n",
       "                       [[ 0.0865,  0.0462,  0.0939],\n",
       "                        [-0.0919, -0.0961,  0.0062],\n",
       "                        [-0.0521, -0.0510, -0.0111]],\n",
       "              \n",
       "                       [[-0.0700, -0.0036, -0.0569],\n",
       "                        [ 0.0262,  0.0147, -0.0706],\n",
       "                        [-0.0468, -0.0068,  0.0596]],\n",
       "              \n",
       "                       [[ 0.0950,  0.0389,  0.0035],\n",
       "                        [-0.0038,  0.0976, -0.0601],\n",
       "                        [-0.0637,  0.0211, -0.0712]],\n",
       "              \n",
       "                       [[ 0.1047, -0.0587, -0.0571],\n",
       "                        [ 0.0638, -0.0199,  0.1011],\n",
       "                        [-0.0457,  0.0523,  0.0165]]]], device='cuda:0')),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0264, -0.1041, -0.0155, -0.0080, -0.0597,  0.0599,  0.0980,  0.1029,\n",
       "                       0.0769, -0.0273], device='cuda:0')),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[-0.0555,  0.0640,  0.0849],\n",
       "                        [-0.0387,  0.0686, -0.0519],\n",
       "                        [-0.0314,  0.0846,  0.1009]],\n",
       "              \n",
       "                       [[-0.0912,  0.0579,  0.0905],\n",
       "                        [ 0.0207,  0.0417,  0.0466],\n",
       "                        [ 0.0040,  0.0636, -0.0699]],\n",
       "              \n",
       "                       [[-0.0106, -0.0333,  0.0550],\n",
       "                        [-0.0712,  0.0477, -0.0453],\n",
       "                        [ 0.0779, -0.0050,  0.0152]],\n",
       "              \n",
       "                       [[ 0.0403,  0.0365,  0.0487],\n",
       "                        [ 0.0659, -0.0261, -0.0425],\n",
       "                        [ 0.0362, -0.1032,  0.0241]],\n",
       "              \n",
       "                       [[ 0.0463,  0.0844,  0.0796],\n",
       "                        [-0.0574, -0.0771, -0.0274],\n",
       "                        [-0.0873,  0.0116,  0.0617]],\n",
       "              \n",
       "                       [[ 0.0595, -0.1022,  0.0428],\n",
       "                        [-0.0517, -0.0460, -0.0749],\n",
       "                        [-0.0307, -0.0426, -0.0533]],\n",
       "              \n",
       "                       [[ 0.0840, -0.0098,  0.0388],\n",
       "                        [-0.0233,  0.0658, -0.0753],\n",
       "                        [-0.0266, -0.0626, -0.0619]],\n",
       "              \n",
       "                       [[-0.0352, -0.1008, -0.0015],\n",
       "                        [-0.1017,  0.0123,  0.0219],\n",
       "                        [ 0.0700, -0.0822, -0.0200]],\n",
       "              \n",
       "                       [[-0.0163, -0.0938,  0.0606],\n",
       "                        [ 0.0556,  0.0448, -0.0126],\n",
       "                        [ 0.0118,  0.0637, -0.0466]],\n",
       "              \n",
       "                       [[ 0.0399,  0.0399, -0.0983],\n",
       "                        [-0.0486, -0.0614, -0.0793],\n",
       "                        [ 0.0806, -0.0364, -0.0314]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0962,  0.0918, -0.0139],\n",
       "                        [ 0.0846,  0.0840, -0.0469],\n",
       "                        [ 0.0030,  0.0532,  0.0990]],\n",
       "              \n",
       "                       [[-0.0152, -0.0375,  0.1048],\n",
       "                        [ 0.0621, -0.0590,  0.0425],\n",
       "                        [-0.0890,  0.0308,  0.0333]],\n",
       "              \n",
       "                       [[-0.0379, -0.0444,  0.0620],\n",
       "                        [ 0.0043, -0.0869,  0.0455],\n",
       "                        [ 0.0428, -0.0541,  0.0792]],\n",
       "              \n",
       "                       [[-0.0794,  0.0188, -0.0636],\n",
       "                        [-0.0927,  0.0626,  0.0807],\n",
       "                        [-0.0929, -0.0692, -0.0473]],\n",
       "              \n",
       "                       [[-0.0862,  0.0073,  0.0880],\n",
       "                        [ 0.0312, -0.0508, -0.0359],\n",
       "                        [ 0.0151, -0.0660, -0.0917]],\n",
       "              \n",
       "                       [[ 0.0025,  0.0017, -0.0628],\n",
       "                        [-0.0693,  0.1003,  0.0123],\n",
       "                        [-0.0154, -0.0457,  0.0629]],\n",
       "              \n",
       "                       [[ 0.0109,  0.0808, -0.0248],\n",
       "                        [-0.0619,  0.0698, -0.0416],\n",
       "                        [ 0.0892, -0.0016,  0.0154]],\n",
       "              \n",
       "                       [[-0.0550, -0.1030, -0.0591],\n",
       "                        [ 0.0369, -0.0881, -0.0172],\n",
       "                        [-0.0067,  0.0202, -0.1046]],\n",
       "              \n",
       "                       [[-0.0283, -0.0080,  0.0128],\n",
       "                        [-0.0294,  0.1021, -0.0171],\n",
       "                        [ 0.0952,  0.0950,  0.0478]],\n",
       "              \n",
       "                       [[ 0.0522,  0.0955, -0.0828],\n",
       "                        [-0.0759,  0.0298, -0.0274],\n",
       "                        [-0.0504, -0.0866,  0.0278]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0800, -0.0388,  0.0490],\n",
       "                        [ 0.0425,  0.0041, -0.0584],\n",
       "                        [ 0.0637,  0.0469, -0.0399]],\n",
       "              \n",
       "                       [[ 0.0783,  0.0774, -0.0548],\n",
       "                        [-0.0905,  0.0364,  0.0632],\n",
       "                        [-0.0097,  0.0931, -0.0140]],\n",
       "              \n",
       "                       [[-0.0017,  0.0719, -0.0121],\n",
       "                        [ 0.0798,  0.0147,  0.0363],\n",
       "                        [-0.0159, -0.0067,  0.0424]],\n",
       "              \n",
       "                       [[-0.0677, -0.0476,  0.0143],\n",
       "                        [-0.0254, -0.0493, -0.0724],\n",
       "                        [-0.0263,  0.1018, -0.0553]],\n",
       "              \n",
       "                       [[ 0.0336,  0.0910,  0.0794],\n",
       "                        [ 0.0004, -0.0268,  0.0919],\n",
       "                        [ 0.0299, -0.0922, -0.0538]],\n",
       "              \n",
       "                       [[-0.0333, -0.0154, -0.0514],\n",
       "                        [ 0.0213,  0.0450, -0.0810],\n",
       "                        [-0.0725,  0.0473, -0.1038]],\n",
       "              \n",
       "                       [[ 0.0357,  0.0243, -0.0970],\n",
       "                        [-0.0038,  0.0808, -0.0060],\n",
       "                        [-0.0183, -0.0780,  0.0002]],\n",
       "              \n",
       "                       [[-0.1040,  0.0775, -0.0894],\n",
       "                        [-0.0242,  0.0422, -0.0087],\n",
       "                        [ 0.0212,  0.0125, -0.0182]],\n",
       "              \n",
       "                       [[-0.0344,  0.0882,  0.0227],\n",
       "                        [ 0.0046,  0.0328,  0.0359],\n",
       "                        [ 0.0428, -0.0023, -0.0043]],\n",
       "              \n",
       "                       [[-0.0127, -0.0773, -0.0081],\n",
       "                        [-0.0806,  0.0699,  0.0538],\n",
       "                        [ 0.0213, -0.1031,  0.0094]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0157,  0.0299,  0.1039],\n",
       "                        [ 0.0805,  0.0347,  0.0960],\n",
       "                        [-0.0068,  0.0682,  0.0067]],\n",
       "              \n",
       "                       [[ 0.0212,  0.0269, -0.0201],\n",
       "                        [ 0.1002,  0.0850, -0.0499],\n",
       "                        [-0.0792,  0.0939,  0.0423]],\n",
       "              \n",
       "                       [[-0.0437, -0.1040, -0.0080],\n",
       "                        [ 0.0363,  0.0949,  0.0454],\n",
       "                        [ 0.0084,  0.0933,  0.0321]],\n",
       "              \n",
       "                       [[ 0.0351, -0.0167,  0.0952],\n",
       "                        [ 0.0441, -0.0134,  0.0365],\n",
       "                        [-0.0654, -0.0914,  0.1045]],\n",
       "              \n",
       "                       [[ 0.0577,  0.0284, -0.0733],\n",
       "                        [ 0.0942, -0.0109,  0.0247],\n",
       "                        [-0.0641, -0.0206,  0.0232]],\n",
       "              \n",
       "                       [[-0.0451,  0.0120, -0.0712],\n",
       "                        [-0.0499, -0.0862,  0.0897],\n",
       "                        [ 0.0077,  0.0157,  0.0631]],\n",
       "              \n",
       "                       [[ 0.0990,  0.0844,  0.0633],\n",
       "                        [-0.0062,  0.0406,  0.0500],\n",
       "                        [ 0.0578, -0.0801, -0.0822]],\n",
       "              \n",
       "                       [[-0.1030,  0.0719,  0.0916],\n",
       "                        [ 0.0770,  0.0210,  0.0068],\n",
       "                        [-0.0492,  0.0960,  0.0736]],\n",
       "              \n",
       "                       [[ 0.0085, -0.1002,  0.0864],\n",
       "                        [-0.0577, -0.0374,  0.0835],\n",
       "                        [-0.0566,  0.0664,  0.0530]],\n",
       "              \n",
       "                       [[-0.0502, -0.1011, -0.0289],\n",
       "                        [-0.0771, -0.1007,  0.0990],\n",
       "                        [-0.0382, -0.0325,  0.0631]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0203, -0.0210, -0.0838],\n",
       "                        [-0.0167, -0.0816,  0.0600],\n",
       "                        [-0.1017,  0.0330, -0.0996]],\n",
       "              \n",
       "                       [[ 0.0871,  0.0620,  0.0176],\n",
       "                        [-0.0005,  0.0366,  0.0967],\n",
       "                        [-0.0850,  0.0598,  0.0066]],\n",
       "              \n",
       "                       [[-0.0348,  0.0989,  0.0312],\n",
       "                        [-0.1045, -0.0365,  0.0455],\n",
       "                        [-0.0637, -0.0831, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0445, -0.0250, -0.0720],\n",
       "                        [ 0.0546,  0.0482,  0.0750],\n",
       "                        [-0.0132, -0.0682,  0.0210]],\n",
       "              \n",
       "                       [[-0.0005,  0.0839,  0.0499],\n",
       "                        [-0.0535,  0.0652,  0.0309],\n",
       "                        [-0.0353, -0.0246, -0.0411]],\n",
       "              \n",
       "                       [[ 0.0839,  0.0479, -0.0162],\n",
       "                        [ 0.0990,  0.0621,  0.0775],\n",
       "                        [-0.0123, -0.0079, -0.1030]],\n",
       "              \n",
       "                       [[-0.0622,  0.0626, -0.0162],\n",
       "                        [ 0.0452, -0.0761,  0.0770],\n",
       "                        [ 0.0932, -0.0652,  0.1025]],\n",
       "              \n",
       "                       [[ 0.0834, -0.0347,  0.0527],\n",
       "                        [-0.1019, -0.0127,  0.0120],\n",
       "                        [ 0.0971,  0.0891, -0.0770]],\n",
       "              \n",
       "                       [[-0.0060, -0.0703,  0.0118],\n",
       "                        [-0.0939,  0.0243,  0.0448],\n",
       "                        [ 0.0362,  0.0475,  0.0973]],\n",
       "              \n",
       "                       [[ 0.0215,  0.0561,  0.0400],\n",
       "                        [-0.0834, -0.0881,  0.0282],\n",
       "                        [-0.0256,  0.0187, -0.0260]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0348, -0.0942, -0.0116],\n",
       "                        [-0.0230,  0.1049,  0.0526],\n",
       "                        [ 0.0155, -0.0655, -0.0775]],\n",
       "              \n",
       "                       [[-0.0882, -0.0565, -0.0952],\n",
       "                        [ 0.0749,  0.1030, -0.0262],\n",
       "                        [-0.0194,  0.0812, -0.0430]],\n",
       "              \n",
       "                       [[ 0.0405, -0.0862,  0.0946],\n",
       "                        [-0.0231,  0.0216, -0.1025],\n",
       "                        [ 0.0028, -0.0191, -0.0654]],\n",
       "              \n",
       "                       [[-0.1022, -0.0482,  0.0850],\n",
       "                        [-0.0249,  0.0013,  0.0881],\n",
       "                        [ 0.0725,  0.1037,  0.0992]],\n",
       "              \n",
       "                       [[ 0.0068, -0.0007,  0.1019],\n",
       "                        [-0.0516, -0.0028, -0.0151],\n",
       "                        [ 0.0251,  0.0227, -0.0484]],\n",
       "              \n",
       "                       [[ 0.0393,  0.0065, -0.0089],\n",
       "                        [ 0.0731,  0.0681,  0.0086],\n",
       "                        [-0.0845, -0.0997, -0.0618]],\n",
       "              \n",
       "                       [[-0.1019,  0.0984,  0.0067],\n",
       "                        [-0.0859, -0.0196,  0.0316],\n",
       "                        [-0.0282, -0.0195, -0.0580]],\n",
       "              \n",
       "                       [[ 0.0903,  0.0222,  0.0905],\n",
       "                        [-0.0008,  0.0610, -0.0851],\n",
       "                        [ 0.0454, -0.0679,  0.0860]],\n",
       "              \n",
       "                       [[-0.0756, -0.0775, -0.0747],\n",
       "                        [-0.0901, -0.0982, -0.0816],\n",
       "                        [ 0.0834, -0.0170,  0.0110]],\n",
       "              \n",
       "                       [[ 0.1016, -0.0575, -0.0296],\n",
       "                        [-0.0792,  0.0763, -0.0946],\n",
       "                        [-0.0717, -0.0175,  0.0172]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0716, -0.0285, -0.0131],\n",
       "                        [ 0.0404,  0.0496,  0.1026],\n",
       "                        [ 0.0815, -0.0811,  0.0548]],\n",
       "              \n",
       "                       [[ 0.0669, -0.1034,  0.0517],\n",
       "                        [-0.0661,  0.0519,  0.0277],\n",
       "                        [-0.0130, -0.0203, -0.0663]],\n",
       "              \n",
       "                       [[-0.0756,  0.0286,  0.0120],\n",
       "                        [-0.0695, -0.0872,  0.0263],\n",
       "                        [ 0.0518,  0.0920, -0.0624]],\n",
       "              \n",
       "                       [[-0.0468, -0.0535,  0.0394],\n",
       "                        [-0.1032, -0.0968, -0.0225],\n",
       "                        [-0.0469,  0.0632, -0.0423]],\n",
       "              \n",
       "                       [[ 0.0079, -0.0743,  0.0857],\n",
       "                        [ 0.0791,  0.0261,  0.0397],\n",
       "                        [-0.0970, -0.0755, -0.0042]],\n",
       "              \n",
       "                       [[-0.0038,  0.0375,  0.0353],\n",
       "                        [-0.0058,  0.0470, -0.0195],\n",
       "                        [ 0.0567, -0.0811,  0.0628]],\n",
       "              \n",
       "                       [[ 0.0920, -0.0012,  0.0577],\n",
       "                        [-0.0686, -0.0029, -0.0319],\n",
       "                        [-0.0011, -0.0377,  0.0756]],\n",
       "              \n",
       "                       [[-0.0444,  0.0339,  0.0574],\n",
       "                        [ 0.0914,  0.0819, -0.0623],\n",
       "                        [-0.0158,  0.0719,  0.0281]],\n",
       "              \n",
       "                       [[ 0.0527,  0.0345, -0.0995],\n",
       "                        [ 0.0492,  0.0846,  0.0502],\n",
       "                        [-0.0460, -0.0230, -0.0375]],\n",
       "              \n",
       "                       [[ 0.0247,  0.0481, -0.0757],\n",
       "                        [ 0.0047, -0.0164,  0.0696],\n",
       "                        [-0.0155, -0.0638,  0.0596]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0473, -0.0076, -0.0295],\n",
       "                        [ 0.0431, -0.0226,  0.0339],\n",
       "                        [-0.0713, -0.0136,  0.0997]],\n",
       "              \n",
       "                       [[-0.0632, -0.0154, -0.0070],\n",
       "                        [ 0.0127, -0.0425,  0.0378],\n",
       "                        [-0.0298,  0.0121,  0.0968]],\n",
       "              \n",
       "                       [[ 0.0928, -0.0310, -0.0587],\n",
       "                        [-0.0648, -0.0171,  0.0053],\n",
       "                        [ 0.0315, -0.0385,  0.0508]],\n",
       "              \n",
       "                       [[-0.0059,  0.0267,  0.1006],\n",
       "                        [ 0.0043,  0.0038, -0.0288],\n",
       "                        [ 0.0757, -0.0913, -0.0507]],\n",
       "              \n",
       "                       [[ 0.0155,  0.0605, -0.1042],\n",
       "                        [-0.0164,  0.0207,  0.0908],\n",
       "                        [ 0.0486,  0.0937, -0.0198]],\n",
       "              \n",
       "                       [[-0.1021,  0.0113,  0.0698],\n",
       "                        [ 0.0023,  0.0175,  0.1023],\n",
       "                        [-0.0985,  0.0177,  0.0319]],\n",
       "              \n",
       "                       [[ 0.0203, -0.0268, -0.0450],\n",
       "                        [ 0.0602,  0.0263,  0.0294],\n",
       "                        [-0.0032, -0.0689,  0.0453]],\n",
       "              \n",
       "                       [[-0.0568, -0.0669, -0.0496],\n",
       "                        [-0.0860, -0.0860, -0.0115],\n",
       "                        [-0.1035,  0.0771, -0.0812]],\n",
       "              \n",
       "                       [[ 0.0388,  0.0436, -0.0417],\n",
       "                        [ 0.0218,  0.0988, -0.0991],\n",
       "                        [ 0.0020,  0.0708,  0.0987]],\n",
       "              \n",
       "                       [[ 0.0291,  0.0927, -0.0563],\n",
       "                        [ 0.0957,  0.0153, -0.0677],\n",
       "                        [ 0.0632,  0.0854, -0.0881]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0550,  0.0276,  0.0898],\n",
       "                        [-0.1000,  0.0537,  0.1012],\n",
       "                        [-0.0326,  0.0334, -0.0937]],\n",
       "              \n",
       "                       [[ 0.0251, -0.0745, -0.1004],\n",
       "                        [ 0.0472,  0.0574,  0.0585],\n",
       "                        [ 0.0787, -0.0280, -0.0772]],\n",
       "              \n",
       "                       [[ 0.0608,  0.0854, -0.0801],\n",
       "                        [-0.0891, -0.0649, -0.0624],\n",
       "                        [ 0.0682, -0.0977,  0.0363]],\n",
       "              \n",
       "                       [[ 0.0164, -0.0749, -0.0913],\n",
       "                        [ 0.0742, -0.0686, -0.0705],\n",
       "                        [ 0.0134, -0.0970, -0.0056]],\n",
       "              \n",
       "                       [[-0.0264, -0.0382, -0.1002],\n",
       "                        [-0.0700,  0.0781, -0.0681],\n",
       "                        [ 0.0513,  0.0793, -0.0005]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0719, -0.0795],\n",
       "                        [ 0.0766,  0.0586,  0.0138],\n",
       "                        [-0.0681, -0.0421,  0.0919]],\n",
       "              \n",
       "                       [[ 0.1040, -0.0838,  0.0443],\n",
       "                        [-0.0645, -0.0177, -0.0066],\n",
       "                        [-0.0829,  0.0002, -0.0278]],\n",
       "              \n",
       "                       [[ 0.0902, -0.0496, -0.0825],\n",
       "                        [ 0.0146,  0.1029,  0.0919],\n",
       "                        [ 0.0430, -0.0990,  0.0571]],\n",
       "              \n",
       "                       [[-0.0232, -0.0808, -0.0401],\n",
       "                        [-0.0986, -0.0460,  0.0428],\n",
       "                        [ 0.0932, -0.0868,  0.0391]],\n",
       "              \n",
       "                       [[ 0.0263, -0.0662, -0.0253],\n",
       "                        [-0.0720, -0.0693,  0.0878],\n",
       "                        [ 0.0978,  0.0376, -0.0204]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0460,  0.0296, -0.0949],\n",
       "                        [-0.0706,  0.0520,  0.0704],\n",
       "                        [-0.0080, -0.0508,  0.0477]],\n",
       "              \n",
       "                       [[ 0.0669, -0.1033, -0.0216],\n",
       "                        [-0.0982, -0.0089,  0.0827],\n",
       "                        [-0.0962, -0.0730, -0.0154]],\n",
       "              \n",
       "                       [[ 0.0324,  0.1028,  0.0432],\n",
       "                        [ 0.0684,  0.0917,  0.0631],\n",
       "                        [-0.0594, -0.0632,  0.0689]],\n",
       "              \n",
       "                       [[-0.0217, -0.0907,  0.0275],\n",
       "                        [-0.0826,  0.0259,  0.1024],\n",
       "                        [ 0.0880, -0.0018,  0.0092]],\n",
       "              \n",
       "                       [[ 0.0211, -0.0368, -0.0622],\n",
       "                        [ 0.1019, -0.0980,  0.0177],\n",
       "                        [-0.0416,  0.0430, -0.0546]],\n",
       "              \n",
       "                       [[ 0.0498, -0.0670, -0.0510],\n",
       "                        [ 0.0851,  0.0093,  0.0934],\n",
       "                        [-0.0686,  0.0710,  0.0133]],\n",
       "              \n",
       "                       [[ 0.0836, -0.0258, -0.0013],\n",
       "                        [ 0.0090, -0.0641,  0.0132],\n",
       "                        [-0.0621,  0.0562,  0.0936]],\n",
       "              \n",
       "                       [[-0.0259, -0.0171,  0.0335],\n",
       "                        [-0.0010, -0.0066, -0.0300],\n",
       "                        [ 0.0807, -0.0218,  0.0941]],\n",
       "              \n",
       "                       [[ 0.0587,  0.0761,  0.0179],\n",
       "                        [-0.0338, -0.0605,  0.0944],\n",
       "                        [-0.0746,  0.0065, -0.0820]],\n",
       "              \n",
       "                       [[-0.1020,  0.0079, -0.0518],\n",
       "                        [-0.0744, -0.0590,  0.1008],\n",
       "                        [ 0.0009,  0.0223, -0.0702]]]], device='cuda:0')),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-3.4592e-02,  7.4214e-02,  8.3869e-02,  9.7997e-05, -9.5552e-02,\n",
       "                       9.9894e-02, -6.8608e-02, -5.3310e-02,  7.5716e-02,  3.4495e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-3.1858e-03,  5.9609e-02,  4.3786e-02],\n",
       "                        [ 1.0345e-01,  9.1889e-02,  2.6615e-02],\n",
       "                        [ 8.9739e-02, -1.0199e-01, -6.5243e-02]],\n",
       "              \n",
       "                       [[-7.4650e-02, -2.3448e-02,  9.7901e-02],\n",
       "                        [ 1.7463e-02, -9.2928e-03, -8.2766e-03],\n",
       "                        [-4.1448e-02, -3.5537e-02,  9.3188e-02]],\n",
       "              \n",
       "                       [[-6.4727e-02,  3.1191e-02,  6.5899e-03],\n",
       "                        [ 1.0097e-01, -5.2907e-02, -2.7799e-02],\n",
       "                        [-6.0417e-02, -1.6772e-02, -6.7101e-02]],\n",
       "              \n",
       "                       [[-6.4501e-02, -1.0251e-02,  1.3209e-02],\n",
       "                        [ 4.7079e-02,  2.8724e-02, -6.0595e-02],\n",
       "                        [-1.0272e-01, -9.7282e-02, -5.4798e-03]],\n",
       "              \n",
       "                       [[ 8.5815e-03,  8.5376e-02,  9.8003e-02],\n",
       "                        [ 1.0504e-01,  8.9716e-02,  8.6197e-02],\n",
       "                        [-1.8161e-03,  4.8513e-02, -7.2040e-03]],\n",
       "              \n",
       "                       [[-8.6111e-02,  3.5675e-02,  1.0182e-01],\n",
       "                        [-4.8656e-02,  8.4851e-02, -6.1608e-02],\n",
       "                        [-7.1501e-02,  7.6708e-02, -8.8073e-02]],\n",
       "              \n",
       "                       [[ 3.4163e-02,  5.0986e-02,  7.4062e-02],\n",
       "                        [-3.6929e-02, -9.0221e-02,  1.0357e-01],\n",
       "                        [-1.3283e-02,  5.1379e-02,  4.7070e-04]],\n",
       "              \n",
       "                       [[-6.4137e-02, -1.0263e-01,  8.8345e-02],\n",
       "                        [-1.0434e-01, -7.0376e-02,  7.4901e-02],\n",
       "                        [ 1.5937e-02, -3.3167e-03, -7.2491e-02]],\n",
       "              \n",
       "                       [[-1.0291e-01, -2.3227e-02,  5.1351e-02],\n",
       "                        [ 4.0638e-02,  4.5168e-02,  8.2953e-02],\n",
       "                        [ 1.3096e-02, -1.8383e-02, -6.8686e-02]],\n",
       "              \n",
       "                       [[-1.6734e-03,  4.7923e-02,  2.7565e-02],\n",
       "                        [ 8.3128e-02,  9.4275e-02,  4.1095e-02],\n",
       "                        [-9.6063e-02, -4.5126e-02,  4.4091e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7482e-02, -5.0695e-03, -6.3307e-02],\n",
       "                        [ 3.5041e-02,  4.1521e-04, -4.7712e-02],\n",
       "                        [ 9.2910e-02, -6.4481e-03,  1.0536e-01]],\n",
       "              \n",
       "                       [[-3.5866e-02,  6.9234e-02,  1.6350e-03],\n",
       "                        [-4.0759e-02,  7.9185e-02, -9.0576e-02],\n",
       "                        [-8.0636e-03,  2.2526e-02, -1.4749e-02]],\n",
       "              \n",
       "                       [[-5.8050e-02, -2.6504e-02,  6.9561e-02],\n",
       "                        [-1.0240e-02, -4.2093e-02, -3.9325e-02],\n",
       "                        [-7.7968e-02,  6.4982e-02, -9.7081e-02]],\n",
       "              \n",
       "                       [[-4.4358e-02,  1.8341e-02,  9.6513e-02],\n",
       "                        [-8.6355e-02,  1.5162e-02, -7.4156e-02],\n",
       "                        [ 7.6225e-02,  7.9287e-02,  6.5358e-02]],\n",
       "              \n",
       "                       [[-4.6205e-02, -8.1298e-02, -6.0655e-02],\n",
       "                        [-3.5201e-02,  4.7742e-02, -1.6121e-02],\n",
       "                        [ 9.1384e-02, -9.9409e-02,  4.8370e-03]],\n",
       "              \n",
       "                       [[-8.9709e-02, -9.9793e-02, -7.5793e-02],\n",
       "                        [ 1.1889e-02, -9.7080e-02, -1.3126e-02],\n",
       "                        [-4.6666e-02, -5.7655e-02,  9.2081e-02]],\n",
       "              \n",
       "                       [[-3.9837e-02, -1.0138e-01,  7.2567e-02],\n",
       "                        [-1.0529e-01, -6.2231e-03, -8.0825e-02],\n",
       "                        [ 5.2955e-02,  3.7248e-02, -1.2442e-02]],\n",
       "              \n",
       "                       [[-3.0468e-02, -7.5241e-02, -7.3488e-02],\n",
       "                        [ 4.0413e-02, -7.4279e-02, -3.7581e-02],\n",
       "                        [ 8.7165e-02, -9.6322e-02,  1.9064e-03]],\n",
       "              \n",
       "                       [[-3.3752e-02,  5.3227e-02, -3.4194e-02],\n",
       "                        [ 8.3760e-02,  3.0688e-02, -5.9336e-02],\n",
       "                        [ 1.9946e-02, -3.2234e-03, -3.3970e-03]],\n",
       "              \n",
       "                       [[-5.7215e-02,  5.3554e-02,  1.7411e-02],\n",
       "                        [-3.3039e-03, -5.5637e-02,  1.0228e-01],\n",
       "                        [-9.3020e-02,  4.5564e-02, -9.5337e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0652e-02,  3.7788e-02,  2.6700e-02],\n",
       "                        [-1.7044e-02,  4.4554e-02, -8.6260e-03],\n",
       "                        [ 3.5886e-02, -9.0184e-02,  5.1549e-02]],\n",
       "              \n",
       "                       [[-2.7376e-02,  6.7645e-02, -9.4860e-02],\n",
       "                        [ 1.0679e-02, -3.4621e-02,  4.1171e-02],\n",
       "                        [-7.5854e-02, -8.2863e-02,  3.4104e-02]],\n",
       "              \n",
       "                       [[-5.7138e-03, -7.5584e-02, -7.7814e-02],\n",
       "                        [-8.2844e-02,  2.1336e-02,  4.4810e-02],\n",
       "                        [-5.0747e-02,  7.0439e-02,  6.6270e-02]],\n",
       "              \n",
       "                       [[ 1.5327e-02, -6.5740e-02, -7.9873e-02],\n",
       "                        [-3.7840e-02, -6.2791e-02,  2.6670e-02],\n",
       "                        [ 6.9492e-02,  9.7215e-02, -5.3288e-02]],\n",
       "              \n",
       "                       [[-5.0659e-02,  1.3221e-02, -2.1592e-02],\n",
       "                        [ 6.8159e-02, -9.7721e-02,  5.2875e-02],\n",
       "                        [ 2.9102e-03,  8.8487e-02, -3.3165e-02]],\n",
       "              \n",
       "                       [[ 3.9005e-02,  2.3178e-02, -6.6168e-02],\n",
       "                        [-7.4181e-02,  6.5268e-02, -4.7596e-02],\n",
       "                        [ 7.7193e-02,  1.6381e-02,  1.0842e-02]],\n",
       "              \n",
       "                       [[ 6.4590e-02, -3.2503e-02, -3.0798e-02],\n",
       "                        [ 3.6522e-02,  2.2114e-02,  5.1135e-02],\n",
       "                        [ 7.0582e-02,  9.0965e-02,  6.1977e-02]],\n",
       "              \n",
       "                       [[-2.9293e-03, -8.9077e-02, -3.7945e-02],\n",
       "                        [-1.0887e-02,  8.1010e-03, -6.1761e-02],\n",
       "                        [-3.9426e-02,  7.5201e-02, -5.9279e-02]],\n",
       "              \n",
       "                       [[ 6.7558e-03,  2.2116e-02,  7.4938e-03],\n",
       "                        [ 1.0450e-02,  9.5926e-02,  7.8034e-02],\n",
       "                        [ 6.2097e-02, -3.8409e-02, -8.0849e-02]],\n",
       "              \n",
       "                       [[ 7.2051e-02, -7.3517e-02, -5.3197e-02],\n",
       "                        [-5.6337e-02, -3.2986e-03,  2.8511e-02],\n",
       "                        [ 3.9902e-02,  1.9763e-02, -8.9111e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0236e-02, -6.1048e-02,  4.9338e-02],\n",
       "                        [-8.4878e-02,  1.6767e-02, -1.0421e-01],\n",
       "                        [ 7.9327e-02,  4.2340e-02, -6.1320e-03]],\n",
       "              \n",
       "                       [[-2.6280e-03, -4.9205e-03, -7.1916e-02],\n",
       "                        [-7.2468e-02,  3.5649e-04,  7.2717e-02],\n",
       "                        [ 4.9096e-02,  6.8943e-02,  8.2182e-02]],\n",
       "              \n",
       "                       [[ 3.6441e-02, -6.9408e-02,  2.6590e-02],\n",
       "                        [-5.3802e-02, -1.7011e-02, -6.2095e-02],\n",
       "                        [ 5.1899e-02, -5.9852e-02,  6.3078e-02]],\n",
       "              \n",
       "                       [[ 4.5522e-02,  5.5107e-02,  6.3701e-02],\n",
       "                        [ 1.7181e-02, -4.4257e-02,  4.3796e-02],\n",
       "                        [ 8.4646e-02,  6.9904e-02, -7.0323e-02]],\n",
       "              \n",
       "                       [[ 3.8775e-02, -3.5905e-02,  8.6265e-02],\n",
       "                        [-4.3144e-02, -1.7648e-02,  3.3556e-02],\n",
       "                        [-9.4757e-02,  2.0985e-02,  5.5935e-02]],\n",
       "              \n",
       "                       [[-1.7949e-02, -9.7010e-02, -1.0263e-01],\n",
       "                        [-7.7073e-02, -9.0874e-02,  4.7362e-02],\n",
       "                        [-2.7632e-02, -2.8733e-02,  7.1877e-02]],\n",
       "              \n",
       "                       [[ 1.9251e-02, -7.5386e-02,  2.0298e-02],\n",
       "                        [ 4.5964e-02, -4.9554e-02,  2.2080e-02],\n",
       "                        [-4.0765e-02, -9.2716e-02, -6.2688e-02]],\n",
       "              \n",
       "                       [[-5.7668e-02,  6.1728e-02,  9.2173e-02],\n",
       "                        [-7.1891e-02,  6.1079e-02, -4.1914e-02],\n",
       "                        [-1.6769e-02,  8.1193e-03,  2.5520e-02]],\n",
       "              \n",
       "                       [[ 1.8176e-02, -9.9413e-02,  2.3039e-02],\n",
       "                        [-1.0427e-01,  1.0138e-01,  1.0298e-01],\n",
       "                        [-9.5258e-02,  4.8900e-02,  7.2118e-02]],\n",
       "              \n",
       "                       [[-6.5053e-02,  2.2796e-02, -5.0176e-02],\n",
       "                        [-7.3576e-02, -4.4797e-02, -4.6502e-02],\n",
       "                        [-7.5590e-02, -2.9424e-03,  1.0194e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4352e-02, -2.9653e-03, -1.0313e-01],\n",
       "                        [ 4.6422e-02,  9.5396e-02, -1.3132e-02],\n",
       "                        [ 9.9133e-02,  1.0246e-01,  3.7506e-02]],\n",
       "              \n",
       "                       [[-9.2655e-02, -2.5608e-02, -2.6146e-02],\n",
       "                        [ 1.8772e-03, -4.1171e-02, -3.9216e-02],\n",
       "                        [-3.4830e-02, -1.0287e-02, -8.5793e-02]],\n",
       "              \n",
       "                       [[-6.0588e-02,  2.7085e-02,  8.3740e-02],\n",
       "                        [ 9.4609e-02,  7.2314e-02, -1.0223e-01],\n",
       "                        [-1.7295e-02, -4.1917e-02,  4.4145e-02]],\n",
       "              \n",
       "                       [[ 1.0539e-01,  7.0268e-02,  6.6630e-02],\n",
       "                        [-5.9465e-02,  9.0608e-02, -7.2212e-02],\n",
       "                        [-7.8276e-02,  4.5301e-02,  8.2210e-02]],\n",
       "              \n",
       "                       [[ 5.7013e-02, -1.0464e-01,  5.7935e-02],\n",
       "                        [-3.5227e-02,  2.4249e-02, -4.7235e-02],\n",
       "                        [-5.5663e-02, -2.8213e-02,  9.1706e-04]],\n",
       "              \n",
       "                       [[ 4.9155e-02, -5.3349e-02, -4.3563e-02],\n",
       "                        [ 5.6823e-02, -4.3111e-02, -7.7047e-02],\n",
       "                        [ 2.9297e-03,  4.6507e-02, -1.3665e-02]],\n",
       "              \n",
       "                       [[ 6.0218e-03,  9.5109e-02,  4.1115e-02],\n",
       "                        [ 3.6094e-03,  7.4453e-02, -1.9632e-02],\n",
       "                        [-5.1817e-02,  3.7844e-02, -7.9696e-02]],\n",
       "              \n",
       "                       [[ 3.1172e-02,  4.5100e-02,  5.7705e-02],\n",
       "                        [ 1.8112e-02,  6.9604e-02,  6.7152e-02],\n",
       "                        [ 5.7228e-02, -7.7775e-02,  1.9399e-02]],\n",
       "              \n",
       "                       [[ 5.1002e-02,  8.6128e-02,  9.3541e-02],\n",
       "                        [-9.7583e-02,  9.0626e-02,  2.5637e-02],\n",
       "                        [-5.7895e-02, -9.2336e-02,  3.9483e-02]],\n",
       "              \n",
       "                       [[ 8.0922e-02,  7.4339e-02,  5.8986e-02],\n",
       "                        [-8.3041e-02, -9.9747e-02, -2.1965e-02],\n",
       "                        [-5.0783e-02, -6.6628e-02, -9.5384e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7278e-02,  3.2916e-02,  4.8524e-02],\n",
       "                        [-5.7729e-02, -6.4047e-02,  4.0164e-03],\n",
       "                        [ 6.1182e-02,  4.5173e-02,  3.3790e-02]],\n",
       "              \n",
       "                       [[-2.8506e-02,  2.1332e-02, -3.4935e-02],\n",
       "                        [ 6.9156e-02,  7.8316e-02,  5.4811e-03],\n",
       "                        [-1.0173e-02,  9.4283e-02, -7.0785e-02]],\n",
       "              \n",
       "                       [[-1.6491e-03,  1.7353e-02, -3.5163e-02],\n",
       "                        [-2.9129e-03, -6.6764e-02,  3.5848e-03],\n",
       "                        [ 5.5377e-02,  7.2068e-02,  7.7562e-02]],\n",
       "              \n",
       "                       [[ 4.5290e-02,  9.8738e-02,  5.2663e-02],\n",
       "                        [ 3.6348e-02,  4.9134e-02,  4.7957e-02],\n",
       "                        [ 1.7021e-02, -8.7825e-02,  3.2459e-03]],\n",
       "              \n",
       "                       [[-2.3686e-02, -4.2756e-02, -4.5790e-02],\n",
       "                        [-3.1657e-02, -4.0481e-02,  9.4244e-02],\n",
       "                        [-3.5677e-02, -1.4447e-03, -1.6497e-02]],\n",
       "              \n",
       "                       [[ 8.2979e-02, -4.8162e-02,  4.2999e-02],\n",
       "                        [-1.0093e-01,  2.2577e-02, -7.1298e-02],\n",
       "                        [ 3.2323e-02,  3.3061e-02,  3.4149e-02]],\n",
       "              \n",
       "                       [[ 1.4467e-02, -3.8066e-02, -6.9589e-02],\n",
       "                        [-6.9240e-02, -1.6727e-02, -2.3726e-02],\n",
       "                        [ 9.6444e-02,  5.4995e-02, -8.0363e-03]],\n",
       "              \n",
       "                       [[ 7.2499e-02, -8.8210e-03, -9.9590e-02],\n",
       "                        [-3.3019e-02,  9.3363e-02,  5.9641e-02],\n",
       "                        [ 1.5685e-03, -5.1978e-02, -6.7031e-03]],\n",
       "              \n",
       "                       [[-1.9531e-03, -7.6793e-02, -1.6903e-02],\n",
       "                        [-6.9181e-02,  4.5708e-02,  3.5646e-02],\n",
       "                        [ 1.1893e-02,  3.5807e-02,  3.0614e-02]],\n",
       "              \n",
       "                       [[-6.7928e-02, -2.1598e-02, -8.6761e-02],\n",
       "                        [ 2.4318e-02,  6.8576e-02, -3.1134e-02],\n",
       "                        [ 3.1216e-03,  8.6872e-02,  5.8808e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.6871e-02,  3.9403e-02,  1.2555e-02],\n",
       "                        [ 9.4489e-02, -7.1964e-02,  7.7763e-02],\n",
       "                        [-1.6416e-02, -5.9796e-02,  8.2572e-02]],\n",
       "              \n",
       "                       [[ 1.0458e-01,  9.0134e-02,  2.9736e-02],\n",
       "                        [ 7.1332e-03, -4.0023e-02,  1.1950e-02],\n",
       "                        [ 1.5923e-02, -3.7493e-02, -5.1610e-02]],\n",
       "              \n",
       "                       [[-6.5209e-02,  3.1979e-02,  4.7112e-02],\n",
       "                        [ 2.2768e-02,  7.4375e-02, -3.0415e-02],\n",
       "                        [-4.5958e-02,  7.4137e-02,  2.3145e-02]],\n",
       "              \n",
       "                       [[ 3.5831e-03,  3.5806e-02, -6.3282e-02],\n",
       "                        [-4.9096e-02,  9.0062e-02, -4.6650e-02],\n",
       "                        [ 7.5525e-03,  8.3784e-02,  9.0047e-02]],\n",
       "              \n",
       "                       [[ 5.9572e-02,  2.5391e-02, -9.1896e-02],\n",
       "                        [-1.0198e-02, -4.2644e-04, -3.3129e-02],\n",
       "                        [-6.5789e-02, -6.8311e-02,  8.3234e-02]],\n",
       "              \n",
       "                       [[-2.5081e-03, -3.8173e-02, -5.5869e-02],\n",
       "                        [-4.0564e-02,  1.0434e-01, -3.3687e-02],\n",
       "                        [-5.8946e-02, -1.0011e-01,  7.6875e-02]],\n",
       "              \n",
       "                       [[ 1.0358e-01,  7.1433e-02,  8.7798e-02],\n",
       "                        [-1.3711e-02, -8.5863e-02, -3.6008e-02],\n",
       "                        [ 1.6788e-02,  9.9890e-02,  1.3550e-02]],\n",
       "              \n",
       "                       [[ 4.8248e-02,  9.2789e-02, -2.9378e-02],\n",
       "                        [-9.2174e-02, -4.8235e-02, -1.0497e-01],\n",
       "                        [ 4.7706e-02, -4.8675e-02, -1.7096e-02]],\n",
       "              \n",
       "                       [[-5.7404e-02, -2.7653e-02,  1.0412e-01],\n",
       "                        [ 2.6501e-02, -4.6162e-02,  8.3045e-02],\n",
       "                        [-6.3447e-02,  2.1413e-02, -7.7518e-02]],\n",
       "              \n",
       "                       [[-1.1069e-03, -7.6250e-02,  6.0112e-02],\n",
       "                        [-1.5654e-02,  1.3902e-02, -6.4866e-02],\n",
       "                        [ 9.8553e-02,  9.9595e-02,  7.2325e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0284e-01, -1.0520e-01, -6.7806e-02],\n",
       "                        [ 5.1734e-02,  5.5495e-02,  3.4034e-02],\n",
       "                        [-8.1217e-02,  6.3682e-02, -9.1045e-02]],\n",
       "              \n",
       "                       [[-1.0005e-01, -4.6418e-02,  5.8140e-02],\n",
       "                        [-6.9155e-02,  6.2557e-02,  5.2812e-02],\n",
       "                        [ 5.1167e-02, -9.8445e-02, -1.6797e-02]],\n",
       "              \n",
       "                       [[-1.0443e-01, -2.2993e-02,  6.3343e-02],\n",
       "                        [-1.5401e-02,  1.0333e-01,  9.4212e-02],\n",
       "                        [-2.4089e-02,  1.2513e-02,  6.7259e-02]],\n",
       "              \n",
       "                       [[-3.6776e-04, -1.3830e-02,  8.1683e-02],\n",
       "                        [-8.1509e-02, -4.4947e-02, -2.1290e-02],\n",
       "                        [ 1.0120e-01, -9.6433e-02, -6.7169e-02]],\n",
       "              \n",
       "                       [[-4.6238e-02, -3.2669e-02, -9.4380e-02],\n",
       "                        [-7.9337e-02,  1.5596e-02,  8.2929e-02],\n",
       "                        [ 1.8345e-02,  1.9790e-02,  8.6985e-02]],\n",
       "              \n",
       "                       [[ 4.8466e-05,  5.5093e-02,  2.0913e-02],\n",
       "                        [-5.3466e-02,  6.5791e-02,  1.5942e-02],\n",
       "                        [-5.5705e-03,  8.2511e-02,  5.2163e-02]],\n",
       "              \n",
       "                       [[ 3.5021e-02, -5.8714e-02, -1.7256e-03],\n",
       "                        [-5.8631e-02, -3.1584e-02, -3.5365e-02],\n",
       "                        [ 1.7487e-02,  3.6679e-03,  3.4636e-02]],\n",
       "              \n",
       "                       [[-8.0888e-02, -2.1745e-02, -1.0986e-02],\n",
       "                        [ 7.9726e-02, -3.9842e-02,  6.0170e-02],\n",
       "                        [ 7.3906e-03,  8.8425e-02, -9.5578e-02]],\n",
       "              \n",
       "                       [[ 6.2559e-02, -3.4210e-02, -6.0706e-02],\n",
       "                        [-7.2854e-02, -4.5351e-03,  2.4479e-02],\n",
       "                        [-4.9055e-02, -2.7548e-02, -8.3194e-03]],\n",
       "              \n",
       "                       [[-4.0110e-02, -5.3651e-03,  7.9551e-02],\n",
       "                        [-9.4540e-02, -5.6668e-02,  3.4395e-02],\n",
       "                        [-5.0489e-02,  3.6983e-03,  9.8933e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.4737e-02, -1.0074e-01,  3.7145e-02],\n",
       "                        [ 1.0451e-01, -8.5954e-02,  8.3557e-02],\n",
       "                        [-2.8247e-02, -4.3649e-02,  5.9466e-02]],\n",
       "              \n",
       "                       [[ 1.0154e-01,  1.8626e-02, -3.8841e-02],\n",
       "                        [-3.7845e-02, -2.8355e-02, -1.0165e-01],\n",
       "                        [ 2.1986e-02,  4.4210e-02, -1.1238e-02]],\n",
       "              \n",
       "                       [[ 1.9838e-02,  4.0065e-02,  4.7735e-02],\n",
       "                        [ 1.9807e-02,  7.1627e-02, -7.0548e-02],\n",
       "                        [ 3.8522e-02,  4.4153e-02, -8.7978e-02]],\n",
       "              \n",
       "                       [[ 5.0743e-02, -8.6644e-02, -5.7290e-02],\n",
       "                        [-5.3581e-02, -3.4642e-02,  5.7163e-02],\n",
       "                        [-1.8742e-02,  4.1927e-02, -6.1408e-02]],\n",
       "              \n",
       "                       [[-5.3500e-02, -9.2085e-02,  5.9274e-02],\n",
       "                        [-7.0599e-02, -9.5813e-02, -6.4243e-02],\n",
       "                        [-9.6528e-02, -5.4077e-02,  4.6860e-02]],\n",
       "              \n",
       "                       [[ 4.0592e-02, -7.6618e-02,  4.8423e-02],\n",
       "                        [ 4.0240e-02, -1.7881e-03,  9.3069e-02],\n",
       "                        [ 1.0354e-01,  9.3136e-02, -9.7763e-02]],\n",
       "              \n",
       "                       [[ 3.4216e-02, -1.0468e-01, -6.5764e-02],\n",
       "                        [ 8.9190e-02, -1.1945e-02, -9.7386e-02],\n",
       "                        [-3.0843e-02,  7.1023e-02, -7.4643e-02]],\n",
       "              \n",
       "                       [[ 7.6101e-02, -4.7832e-02,  6.4449e-02],\n",
       "                        [ 8.0102e-03,  5.0224e-02,  9.0189e-02],\n",
       "                        [-6.3209e-02,  7.7380e-02,  1.6972e-02]],\n",
       "              \n",
       "                       [[-2.5940e-02, -7.3719e-02,  7.0890e-03],\n",
       "                        [ 4.4042e-02,  8.5555e-02,  3.0635e-02],\n",
       "                        [ 5.7880e-02, -9.5381e-02, -9.8597e-02]],\n",
       "              \n",
       "                       [[ 5.1447e-03, -9.8288e-02, -1.7143e-02],\n",
       "                        [-7.3014e-02,  4.7089e-02, -8.6842e-02],\n",
       "                        [-5.7935e-02,  6.9073e-02, -4.7676e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.2988e-02,  7.3065e-02,  1.0205e-01],\n",
       "                        [ 2.2765e-02, -3.6318e-02, -4.9343e-02],\n",
       "                        [-7.3111e-02,  1.5608e-02,  1.8963e-04]],\n",
       "              \n",
       "                       [[-9.5022e-03, -6.1163e-02,  9.5446e-02],\n",
       "                        [-6.8442e-02, -4.8474e-02,  1.0098e-01],\n",
       "                        [ 4.7112e-03,  5.5647e-03,  5.2696e-02]],\n",
       "              \n",
       "                       [[ 3.6329e-03, -4.2520e-03,  4.1681e-02],\n",
       "                        [ 3.5554e-02, -8.0169e-02,  2.1340e-02],\n",
       "                        [-4.3323e-02,  9.5883e-02,  3.0947e-02]],\n",
       "              \n",
       "                       [[ 3.1953e-02,  9.2427e-02, -2.0019e-02],\n",
       "                        [ 5.5868e-02, -9.7061e-02,  4.1426e-02],\n",
       "                        [ 8.2580e-02, -5.0448e-02, -1.7309e-02]],\n",
       "              \n",
       "                       [[ 1.8003e-02, -4.5725e-02, -7.5070e-02],\n",
       "                        [-5.5337e-02, -8.8486e-02,  3.1482e-02],\n",
       "                        [-3.0436e-02,  8.9569e-02, -6.4214e-02]],\n",
       "              \n",
       "                       [[ 7.4526e-02, -4.6543e-02, -1.0456e-01],\n",
       "                        [ 3.7556e-02, -5.0550e-02, -7.4575e-02],\n",
       "                        [-5.7764e-02, -6.0725e-02, -1.6246e-02]],\n",
       "              \n",
       "                       [[ 3.6112e-02,  2.5616e-02,  5.0173e-02],\n",
       "                        [ 5.9264e-02,  2.0742e-02, -4.2329e-03],\n",
       "                        [-9.0870e-02,  5.7648e-02, -9.2219e-02]],\n",
       "              \n",
       "                       [[-1.0881e-02, -3.2524e-03,  8.2642e-02],\n",
       "                        [-7.8339e-02, -3.5463e-02,  5.1857e-02],\n",
       "                        [ 3.4284e-02,  1.8862e-02,  5.6781e-02]],\n",
       "              \n",
       "                       [[ 6.8744e-02,  8.5030e-02,  9.4461e-02],\n",
       "                        [-2.1698e-03,  1.0119e-01, -2.3643e-02],\n",
       "                        [ 7.5013e-02,  6.6529e-02, -2.9248e-02]],\n",
       "              \n",
       "                       [[-2.4749e-02, -8.7956e-02,  2.1685e-02],\n",
       "                        [-1.4870e-02,  4.5089e-02,  6.7413e-02],\n",
       "                        [ 8.1741e-02, -2.6749e-02,  7.3644e-02]]]], device='cuda:0')),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([-0.0375, -0.0148, -0.0518,  0.0928, -0.0006, -0.0181, -0.0411,  0.0685,\n",
       "                      -0.0010,  0.0650], device='cuda:0')),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[-0.0150, -0.0165, -0.0051,  ...,  0.0055,  0.0123,  0.0162],\n",
       "                      [ 0.0088, -0.0184,  0.0147,  ...,  0.0197,  0.0146, -0.0007],\n",
       "                      [ 0.0096, -0.0145,  0.0133,  ..., -0.0167,  0.0019, -0.0165]],\n",
       "                     device='cuda:0')),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([0.0004, 0.0188, 0.0152], device='cuda:0'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from going_modular import model_setup\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Instantiate model\n",
    "model_1 = model_setup.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model. \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "def train_step(model: nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer, \n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for one epoch.\n",
    "    \n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model instance.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "            If not specified, the device will be \"cuda\" if available.\n",
    "    \n",
    "    Returns:\n",
    "        A Tuple of training loss and training accuracy metrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Instantiate training loss and accuracy\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        \n",
    "        # Calculate loss and accumulate train loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "    \n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "    \n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "  \n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "  \n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "                # Send data to target device\n",
    "                X, y = X.to(device), y.to(device)\n",
    "        \n",
    "                # 1. Forward pass\n",
    "                test_pred_logits = model(X)\n",
    "\n",
    "                # 2. Calculate and accumulate loss\n",
    "                loss = loss_fn(test_pred_logits, y)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Calculate and accumulate accuracy\n",
    "                test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "                test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "          \n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List[float]]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "  }\n",
    "  \n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "      \n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains the functionality for saving a PyTorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "  \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "  Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "  \n",
    "  Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "  \"\"\"\n",
    "  # Create target directory\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "  \n",
    "  # Create model save path\n",
    "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  # Save the model state_dict()\n",
    "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, evaluate and save the model (script mode) -> train.py\n",
    "Let's create a file called train.py to leverage all of our other code scripts to train a PyTorch Model\n",
    "Essentially replicate the functionality of 04 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "\"\"\"\n",
    "Contains the functionality for training a PyTorch image classification model.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import data_setup, engine, model_setup, utils\n",
    "\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"C:\\\\Users\\\\jakev\\\\Code\\\\Learn_Pytorch\\\\Practice\\\\data\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\jakev\\\\Code\\\\Learn_Pytorch\\\\Practice\\\\data\\\\test\"\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create DataLoaders and get class names\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=data_transforms,\n",
    "                                                                               batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create model\n",
    "model = model_setup.TinyVGG(input_shape=3, \n",
    "                            hidden_units=HIDDEN_UNITS, \n",
    "                            output_shape=len(class_names)).to(device)\n",
    "\n",
    "# Set up loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Start timer\n",
    "start_time = timer()\n",
    "\n",
    "# Start training with engine.py\n",
    "engine.train(model=model,\n",
    "             train_dataloader=train_dataloader,\n",
    "             test_dataloader=test_dataloader,\n",
    "             optimizer=optimizer,\n",
    "             loss_fn=loss_fn,\n",
    "             epochs=NUM_EPOCHS,\n",
    "             device=device)\n",
    "\n",
    "# End timer \n",
    "end_time = timer()\n",
    "total_time = end_time - start_time\n",
    "print(f\"[INFO] Total training time: {total_time:.3f} seconds\")\n",
    "\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"05_going_modular_script_mode_tinyvgg_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python going_modular/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
